word_tokenize(): nltk에서 지원하는 영어 코퍼스를 토큰화하기 위한 도구
from nltk.tokenize import word_tokenize

WordPunctTokenizer: nltk에서 지원하는 영어 코퍼스를 토큰화하기 위한 도구. 구두점을 별도로 분류함.
from nltk.tokenize import WordPunctTokenizer

text_to_word_sequence: 케라스에서 지원하는 토큰화도구. 모든 알파벳을 소문자로 바꾸면서 마침표나 컴마, 느낌표 등의 구두점을 제거. 하지만 don't와 같은 아포스트로피는 보존함
from tensorflow.keras.preprocessing.text import text_to_word_sequence

TreebankTokenizer: 표준으로 사용되는 토큰화 방법 중 하나인 Penn Treebank Tokenization의 규칙으로 사용되는 nltk에서 지원하는 토큰화 도구. 다음의 두 규칙을 따른다.
규칙 1. 하이푼으로 구성된 단어는 하나로 유지한다.
규칙 2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.
from nltk.tokenizer import TreebankWordTokenizer

sent_tokenize: NLTK에서 지원하는 영어 문장의 토큰화를 수행하는 도구
from nltk.tokenize import sent_tokenize
# NLTK는 단순히 마침표를 구분자로 하여 문장을 구분하지 않는다.

split_sentences(): kss에서 지원하는 문장 토큰화 도구
import kss

pos_tag: NLTK에서 사용하는 품사 태깅 도구. PennTreebank POS Tags.
from nltk.tag import pos_tag

KoNLPy: 한국어 자연어 처리를 위한 파이썬 패키지.

Okt: KoNLPy에서 지원하는 형태소 분석기. Okt(Open Korea Text)외에 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma) 등이 있다.
from konlpy.tag import Okt
from konlpy.tag import Kkma

